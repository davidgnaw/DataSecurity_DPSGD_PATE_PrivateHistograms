{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "188262ed-3562-483d-a0cd-51ea3729802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv #import csv\n",
    "import numpy as np #for laplace --- np.random.laplace(loc=0.0, scale=1.0, size=None)\n",
    "import matplotlib.pyplot as plt #plotting\n",
    "import numpy as np #for laplace --- np.random.laplace(loc=0.0, scale=1.0, size=None)\n",
    "import pandas as pd #for binning purposes\n",
    "import random #for synthetic dataset\n",
    "from random import randrange\n",
    "\n",
    "\n",
    "def hist_create(inp, epsilon, out, num_queries):\n",
    "    # inp = input dataset file (csv format)\n",
    "    # epsilon = privatcy budge ranging from 0 to 1\n",
    "    # out_data = output synthetic dataset file (csv format)\n",
    "    # num_queries = number of random queries to run for reporting query error\n",
    "    # out_error = output relative error\n",
    "    \n",
    "    # create histogram based on input dataset file\n",
    "    \n",
    "    df = pd.read_csv(inp)\n",
    "    \n",
    "    #convert pandas to 3D array\n",
    "    tD_arr = df.to_numpy()\n",
    "\n",
    "    #calculate bins\n",
    "\n",
    "     # determine number of equi-width bins using Freedman-Diaconis rule\n",
    "    q75, q25 = np.percentile(df, [75,25])\n",
    "    iqr = q75 - q25\n",
    "\n",
    "    bin_width = 2 * iqr * len(df)**(-1/3)\n",
    "    num_bins = round(((df.max() - df.min()) / bin_width).max()) # get the max which is the main attribute\n",
    "\n",
    "\n",
    "    hist, edges = np.histogramdd(tD_arr, bins = num_bins)\n",
    "\n",
    "    #apply laplace \n",
    "    lp = np.random.laplace(0, 1/epsilon, len(df)) #sensitivity at most 1 and privacy budget user defined epsilon\n",
    "    #get laplace distribution and get counts\n",
    "    count, bins = np.histogram(lp, num_bins, density = True)\n",
    "\n",
    "    #add laplace noise to 3D hist\n",
    "    df_hist = hist + count\n",
    "\n",
    "    #generate synthetic dataset\n",
    "    coord = []\n",
    "\n",
    "    for i in range(len(df_hist)): # for x variable (which array)\n",
    "        for j in range(len(df_hist[i])): # for y variable (which row)\n",
    "            for k in range(len(df_hist[i][j])): # for z variable (which column) also the specific number to iterate based on how many there is for that unit\n",
    "                if df_hist[i][j][k] > 0:\n",
    "                    for itr in range(0, int(df_hist[i][j][k])):\n",
    "                        point = [round(random.uniform(edges[0][i], edges[0][i+1]),0), round(random.uniform(edges[1][j], edges[1][j+1]),0), round(random.uniform(edges[2][k],edges[2][k+1]),0)]\n",
    "                        coord.append(point)\n",
    "\n",
    "    #convert synthetic dataset into pandas dataframe for sorting and adding tags\n",
    "    df_syn = pd.DataFrame(coord)\n",
    "\n",
    "    col_names = [df.keys()[0], df.keys()[1], df.keys()[2]] #changing column names to match\n",
    "    df_syn.columns = col_names\n",
    "\n",
    "    #sort original df and new df similarly\n",
    "    df_s = df.sort_values(by = [df.keys()[0], df.keys()[1], df.keys()[2]])\n",
    "    df_syn_s = df_syn.sort_values(by = [df_syn.keys()[0], df_syn.keys()[1], df_syn.keys()[2]])\n",
    "\n",
    "\n",
    "    #change back to numpy for easy comparison with arithmetic\n",
    "    true = pd.DataFrame(df_s).to_numpy()\n",
    "    synth = pd.DataFrame(df_syn).to_numpy()\n",
    "\n",
    "    #calculate random queries accuracy\n",
    "    queries = num_queries\n",
    "    que_result = []\n",
    "\n",
    "\n",
    "    for i in range(0, queries):\n",
    "        random_query = randrange(len(df))\n",
    "        que_result.append(abs(true[random_query] - synth[random_query])/synth[random_query])\n",
    "\n",
    "    que_error = sum(que_result)/queries\n",
    "\n",
    "    #calculate relative error\n",
    "    avg_error = abs((sum(true) - sum(synth)))/ sum(synth)\n",
    "    \n",
    "    #write to csv synthetic dataset\n",
    "    df_syn.to_csv(out)\n",
    "    \n",
    "    print('Synthetic dataset is outputted at ', out)\n",
    "    #manually print relative error and query error\n",
    "    #queue error\n",
    "    all_que_error = []\n",
    "    que_counts = 0\n",
    "    for i in range(0,len(que_error)):\n",
    "        if que_error[i] > 0:\n",
    "            all_que_error.append(que_error[i])\n",
    "            que_counts = que_counts + 1\n",
    "        \n",
    "    print('Queue Error with ', num_queries, ' queues: ', sum(all_que_error)/que_counts)\n",
    "    \n",
    "    \n",
    "    #relative error\n",
    "    all_avg_error = []\n",
    "    avg_counts = 0\n",
    "    for i in range(0,len(avg_error)):\n",
    "        if avg_error[i] > 0:\n",
    "            all_avg_error.append(avg_error[i])\n",
    "            avg_counts = avg_counts + 1\n",
    "        \n",
    "    print('Relatie Error: ', sum(all_avg_error)/avg_counts)\n",
    "    \n",
    "\n",
    "    \n",
    "def main():\n",
    "    \n",
    "    print(\"Input CSV Input File in format filename.CSV\")\n",
    "    inp = str(input())\n",
    "    \n",
    "    print(\"Input privacy budget epsilon from 0 to 1\")\n",
    "    epsilon = float(input())\n",
    "    \n",
    "    print(\"Input CSV Output File in format filename.CSV, make sure Output File is in same directory as program\")\n",
    "    out = str(input())\n",
    "    \n",
    "    print(\"Input number of random queries to test for query error out of\" + len(pd.read_csv(inp)))\n",
    "    num_queries = int(input())\n",
    "    \n",
    "    hist_create(inp, epsilon, out, num_queries)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57acd622-9d82-42cc-871f-97d8b1d29c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32561"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.read_csv('adult2.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06e8f275-7ad8-4db0-bfee-d82959eddcec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'queries' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xw/gjkqcy4x1gqgcyvc45ys8srw0000gn/T/ipykernel_47757/851344139.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'queries' is not defined"
     ]
    }
   ],
   "source": [
    "len(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41164496-bb86-4920-9e20-f6a226e6cf6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
